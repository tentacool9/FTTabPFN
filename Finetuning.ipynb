{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2e5ce6-24da-44c4-99e8-7a6a664aa4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import sys\n",
    "sys.path.append('../TabPFN/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb02ce58-9a56-4598-a744-87ce2df66135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn.model.loading import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c63c7c2a-99af-405f-9db1-ac7739d9128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetuning_scripts.finetune_tabpfn_main import fine_tune_tabpfn_original\n",
    "from sklearn.datasets import load_iris, load_wine, fetch_openml,load_digits\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabpfn import TabPFNClassifier\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabpfn.model.gatedtransformerv2 import GatedPerFeatureTransformer, DebugInfo\n",
    "from tabpfn.model.transformer import PerFeatureTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d18a2f9-4bfa-46fc-b0ca-d4483aa6f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "phones = pd.read_csv('train.csv')\n",
    "X = phones.drop(['price_range'],axis=1)\n",
    "y = phones['price_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c35aca17-d990-4f0e-b9a0-123053be4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# X, y = load_wine(return_X_y=True, as_frame=True)\n",
    "# X, y = load_wine(return_X_y=True, as_frame=True)\n",
    "# Load MNIST from OpenML; as_frame=True returns a Pandas DataFrame.\n",
    "# mnist = fetch_openml('mnist_784', version=1, as_frame=True)\n",
    "# X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "# y = y.astype(int)\n",
    "# digits = load_digits()\n",
    "# X, y = pd.DataFrame(digits.data), pd.Series(digits.target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.33,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6792bc-ddd1-46bc-a527-0253f14b5c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No feature gate parameters found in state_dict; using random initialization for feature_gate.\n",
      "Warning: No sample gate parameters found in state_dict; using random initialization for sample_gate.\n",
      "Loaded Gated Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   0%| | 2/10000 [00:26<72:49:24, 26.22s/it, Best Val. Loss=1.24, Best Val. Score=-1.24, Training Los"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Finetune\n",
    "save_path_to_fine_tuned_model = \"./fine_tuned_model_new_20_03_gated.ckpt\"\n",
    "fine_tune_tabpfn_original(\n",
    "    path_to_base_model=\"auto\",\n",
    "    save_path_to_fine_tuned_model=save_path_to_fine_tuned_model,\n",
    "    # Finetuning HPs\n",
    "    time_limit=1000,\n",
    "    finetuning_config={\"learning_rate\": 0.00001, \"batch_size\": 8,\"min_patience\": 30,\"max_patience\": 100},\n",
    "    validation_metric=\"log_loss\",\n",
    "    # Input Data\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    categorical_features_index=None,\n",
    "    device=\"cuda\",  # use \"cpu\" if you don't have a GPU\n",
    "    task_type=\"multiclass\",\n",
    "    gated=True,\n",
    "    # Optional\n",
    "    show_training_curve=True,  # Shows a final report after finetuning.\n",
    "    logger_level=-100,  # Shows all logs, higher values shows less\n",
    "    use_wandb=False,  # Init wandb yourself, and set to True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ccfab1-a1f4-440c-bc9e-d9b9c834950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_to_fine_tuned_model = \"./fine_tuned_model_new_20_03_gated.ckpt\"\n",
    "gated_model = TabPFNClassifier(\n",
    "    model_path=save_path_to_fine_tuned_model,\n",
    "    gated=True\n",
    ")\n",
    "# Then, use gated_model in your fine-tuning pipeline.\n",
    "clf = gated_model.fit(X_train, y_train)\n",
    "print(\"Log Loss (Default):\", log_loss(y_test, clf.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abcd2c8-a689-4267-bf00-d3f4888ae147",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,np.argmax(clf.predict_proba(X_test),axis=1)),\\\n",
    "precision_score(y_test,np.argmax(clf.predict_proba(X_test),axis=1),\\\n",
    "average='weighted'),\\\n",
    "recall_score(y_test,np.argmax(clf.predict_proba(X_test),axis=1),average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a9953-2025-486d-8a3e-e5fca10dffb2",
   "metadata": {},
   "source": [
    "## OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0285bd-8b04-498d-8f65-d436ef28b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "X, y = load_wine(return_X_y=True, as_frame=True)\n",
    "# X, y = load_wine(return_X_y=True, as_frame=True)\n",
    "# Load MNIST from OpenML; as_frame=True returns a Pandas DataFrame.\n",
    "# mnist = fetch_openml('mnist_784', version=1, as_frame=True)\n",
    "# X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "# y = y.astype(int)\n",
    "# digits = load_digits()\n",
    "# X, y = pd.DataFrame(digits.data), pd.Series(digits.target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.33,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Finetune\n",
    "save_path_to_fine_tuned_model = None\n",
    "fine_tune_tabpfn_original(\n",
    "    path_to_base_model=\"auto\",\n",
    "    save_path_to_fine_tuned_model=save_path_to_fine_tuned_model,\n",
    "    # Finetuning HPs\n",
    "    time_limit=1000,\n",
    "    finetuning_config={\"learning_rate\": 0.00001, \"batch_size\": 8,\"min_patience\": 30,\"max_patience\": 100},\n",
    "    validation_metric=\"log_loss\",\n",
    "    # Input Data\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    categorical_features_index=None,\n",
    "    device=\"cuda\",  # use \"cpu\" if you don't have a GPU\n",
    "    task_type=\"multiclass\",\n",
    "    # Optional\n",
    "    show_training_curve=True,  # Shows a final report after finetuning.\n",
    "    logger_level=-100,  # Shows all logs, higher values shows less\n",
    "    use_wandb=False,  # Init wandb yourself, and set to True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ad780-9ef6-4851-974e-ac37481469bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_to_fine_tuned_model = 'basic_ft.ckpt'\n",
    "reg_model = TabPFNClassifier(\n",
    "    model_path=save_path_to_fine_tuned_model,\n",
    ")\n",
    "# Then, use gated_model in your fine-tuning pipeline.\n",
    "clf = reg_model.fit(X_train, y_train)\n",
    "print(\"Log Loss (Default):\", log_loss(y_test, clf.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01374a1-2a9c-4f7f-b26c-695d9768451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,np.argmax(clf.predict_proba(X_test),axis=1)),\\\n",
    "precision_score(y_test,np.argmax(clf.predict_proba(X_test),axis=1),\\\n",
    "average='weighted'),\\\n",
    "recall_score(y_test,np.argmax(clf.predict_proba(X_test),axis=1),average='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
